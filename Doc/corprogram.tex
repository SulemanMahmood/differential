\section{Correlating Program} \seclabel{Correlating}

In this section we will describe how we construct our correlating program $P \bowtie P'$. The process of correlating attempts to find a better interleaving of programs for a more precise differentiation. The building process also find and instruments $P \bowtie P'$ with the required differencing points $DP$ which allow reporting of difference and correlation points $CP$ which define the locations for out partitioning. We also allow a user defined delection of $DP$ and $CP$.

\subsection{The Correlating Program $P \bowtie P'$ }\sseclabel{CorrelatingProgram}
The idea of a correlating program is similar to that of
self-composition~\cite{BartheDArgenioRezk04,AikenTerauchi05}, but the way in
which statements in the correlating program are combined is carefully designed to
keep the steps of the two programs close to each other. Rather than having
the patched program sequentially composed after the original program, our
correlating program interleaves the two versions. Analysis of the correlating program can then recover equivalence between values of correlated variables even when
equivalence is \emph{temporarily} violated by an update in one version, as
the corresponding update in the other version follows shortly thereafter.

We will generally describe the process of constructing the correlating program. A more elaborate and formal description of the algorithm can be found in \algref{CorrelatingConstruction}. The correlating program is an optimized structure where not all pairs of $(\sigma,\sigma')$ are considered, but only pairs that result from a controlled execution, where correlating instructions (according to $DP$) in $P$ and $P'$ will execute together. This will allow for superior precision. As said, the main idea is to create one program which contains both versions. The correlating starts out as (exactly) the older version $P$ (after being converted to our guarded instruction form). Afterwards a syntactic diff with $P'$ (also transformed to guarded mode) is computed (the programs are not combined just yet). In fact, this is the point where $DP$ is created as the diff supplies us with the correlation between labels we desire. Then $P'$'s instructions are interleaved into the guarded $P$ while maintaining the correlation found by the diff (matched instructions will appear consequentially). Just before a patched instruction is interleaved into the correlating, all variables that appear in it are tagged, as to make sure that the patched instructions will only affect patched variables. Thus we maintain the semantics of running both programs correctly while achieving a new construct that will allow us to analyze change more easily and precisely. \TODO{\figref{} holds a complete correlating program of the program in \figref{} and it's patched version, a graphic description as a controlled automata is shown in \figref{}}. Note that if we view the general correlating program as a concurrent program, then this optimized program can be viewed as a partial-order reduction applied over the concurrent program. One final observation regarding the correlating program is that it is a legitimate program that can be run to achieve the effect of running both versions. This ability allows us to use dynamic analysis and testing techniques such as fuzzing \ref{} and directed automated testing \ref{} which may produce input that lead to states approximated by $\triangle$.


\subsection{General Product Program} \sseclabel{ProductProgram}
A simple approach for a joint analysis is to construct a product program $P \times P'$ where at every point during the execution we can perform a program step (as defined in \defref{Program}) of either programs. The product program has a duo-state $(\sigma,\sigma')$ and each step updates $(\sigma,\sigma')$ accordingly. The product program can also be seen as a concurrent run $P||P'$ where every interleaving is possible. The product program emphasizes the fact that, as described in~\secref{ConcreteSem}, the notion of $\triangle$ is unclear without an established variable and label correspondence. Choosing the \b{location} where $\triangle$ is checked is a key part of identifying differences. Consider~\figref{ProductProgramExample}, which presents a product automata of the simple program with itself, we see that even in this trivial program, although it is clear that $\triangle = \emptyset$, checking for difference in any of the non-correlating states will result in a false difference being reported. As this example demonstrates, selecting a correct label correspondence is crucial for a meaningful delta, we will elaborate on our approach for choosing $DP$ in \subref{DiffPoints}.

\begin{figure}[ht] \figlabel{ProductProgramExample}
\lstset{numbers=left, language=C, basicstyle=\ttfamily\scriptsize,emph={},emphstyle=\textbf,escapechar=\%}
\begin{lstlisting}
void foo() {
    int x = 0;
}
\end{lstlisting}
\caption{Program $P$}
\centering
%\includegraphics[scale=1]{figures/product_program_example.png}
%\caption{Product Program $P \times P$}
\end{figure}

\subsection{Program Correspondence and Differential Points} \sseclabel{DiffPoints}
Selecting the point where $\triangle$ is computed is vital for precision. As mentioned, a natural selection for diff points would be at the endpoints of traces but that loses meaning under the collecting semantics. A possible translation of this notion under the collecting semantics would be to compute delta between \emph{all} the endpoints of the two programs i.e. $DP = \{(fin,fin') | fin \in exit(P), fin' \in exit(P') \}$ somehow differentiating the final states of the programs. This approach is problematic for two reasons:
\begin{enumerate}
\item Comparing all endpoints results in a highly imprecise delta. This is shown by the simple exercise of taking program with 2 endpoints and comparing it with itself.
\item This choice for $DP$ may result in missing key differences between versions. If at some point during the calculation existed a delta that failed reaching the final state - it will be ignored. An interesting example for this is an array index receiving different bounds after a patch (but later overwritten so that it is not propagated to some final state).
\end{enumerate}
Alternatively, the brute force approach where we might attempt to capture more potential diffs by selecting a diff-point after every line, will result in a highly inaccurate result as, for instance in \figref{ProductProgramExample}, many diffs will be reported although there is no difference.
Finally, we must be careful with the selection of $DP$ as it affects the soundness of our analysis: we might miss differences if we did not correctly place diff-points in locations where delta exists.
\TODO{Our approach employs standard syntactic diff algorithm \ref{Diff} for producing the correlation.} \TODO{This selection for $DP$ assures soundness}. The Diff approach works well since two versions of the same software (and especially those that originate from subsequent check-ins to a code repository) are usually similar. Another important factor in the success of the diff is the guarded instruction format for our programs (as defined in \defref{Program}). Transforming both programs to a our format helps remove a lot of the "noise" that a patch might introduce yet it is superior to low level intermediate representation as it retains many qualities (such as variable names, conditions, no temporaries, etc.). \TODO{See \appref{Guarded} for examples illustrating said benefits and qualities}. There are alternate ways for creating the correspondence such as \TODO{graph equivalence, etc.}, this could be a subject of future research. Calculating delta according to $DP$ over the product automata is a complex task as it allows both programs to advance independently. We formulate the \emph{correlating program} as a restricted product automata where we advance the programs while keeping the correlation allowing for a superior calculation of delta using our correlating abstract domain later defined in \secref{AbstractSem}.


\subsection{Analyzing Correlating Programs}\sseclabel{AnalyzeCorrelating}
Analyzsis of a guarded correlating program has certain caveats.
\begin{figure}[ht]\figlabel{GuardProblemExample}
\lstset{numbers=left, language=C, basicstyle=\ttfamily\scriptsize,emph={},emphstyle=\textbf,escapechar=\%}
\begin{lstlisting}
l:  guard g = (i>0);
    if (g) i--;
    if (g) goto l;
\end{lstlisting}
\caption{example program illustrating guard analysis caveat}
\end{figure}
In order to correctly analyze the program in \figref{GuardProblemExample} we need our analysis to assume $(i>0)$ whenever taking the true branch on the \scode{if (g)} instruction and $(i<=0)$ when taking the false branch. However, since the \scode{i--} instruction invalidates this assumption we would need to update the guard assumption to $(i>-1)$ which would complicate the analysis as we would need to consider updating the guard assumption while widening etc. Our solution simply incorporates the guard's assumption the first time it encounters the guard and allows it to flow to the rest of the nodes. We are not in danger of losing the assumption during the following join as our join employs a partition-by-equivalence strategy and will not join the two states where ${g,i>0}$ and ${\neg{g},i<=0}$.

%\subsection{Instrumented Collecting Semantics Correlating}\label{Se:Naive}
%In this section we say why instrumenting the program with $x \equiv x'$ is cruicial since otherwise we are unable to establish %equality. Take for instance a program where the analysis result will be $ 0 < x < 9 and 0 < x' <9 $...  