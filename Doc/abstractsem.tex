\section{Abstract Correlating Semantics}\seclabel{AbstractSem}

In this section, we introduce our correlating abstract domain which allows bounded representation of product program state while maintaining equivalence between correlated variables. This comes at the cost of an acceptable lose of precision of other state information. We represent variable information using standard relational abstract domain. As our analysis is path sensitive, we allow for a set of abstract sub-states, each adhering to a certain path in the product program. This abstraction is similar to the trace partitioning domain as described in \cite{MauborgneRival07}. To assure we only consider correlated paths from the product programs (that agree on input), our abstraction will initially assume equality on all inputs. This power-set domain records precise state information but does not scale due to exponential blow-up of number of paths. To reduce state size, we define a special join operation that dynamically partitions the abstract state according to the set of equivalences maintained in each sub-state and joins all sub-states in the same partition together (using the sub-domain lossy join operation). This equivalence criteria allows separation of equivalence preserving paths thus achieving better precision. We start off by abstracting the correlating trace semantics in \ssecref{ConcreteCorrelatingSemantics}.

In the following, we assume an abstract relational domain $(\A{D}, \sqsubseteq_{D})$ equipped with operations $\sqcap_{D}$, $\sqcup_{D}$ and $\nabla_{D}$, for representing sets of concrete states in $\Sigma_{P \times P'}$. We separate the set of program variables into original program variables denoted $Var$ (which also include a special added variable for return value, if such exists) and the added guard variables denoted $Guard$ that are used for storing conditional values alone ($Guard$ also include a special added variable for return flag). We assume the abstract values in $\A{D}$ are constraints over the variables and guards (we denote $\A{D}_{Guard}$ for abstraction of guards and $\A{D}_{Var}$ for abstracting original variables), and do not go into further details about the particular abstract domain as it is a parameter of the analysis. We also assume that the sub-domain $\A{D}$ allows for a sound over-approximation of the concrete semantics (given a sound interpretation of program operations). In our experiments, we use the polyhedra abstract domain \cite{} and the octagon abstract domain \cite{Mine07}.

\paragraph{Correlating Abstract State} \deflabel{CorrelatingAbstractState}
A correlating abstract program state $\A{\sigma} \in Lab_{\times} \rightarrow 2^{\A{D}_{Guard} \times \A{D}_{Var}}$, is a set of pairs $\langle ctx, data \rangle \in \C{\Sigma}$ mapped to a product program label $l_{\times}$, where $ctx \in \A{D}_{Guard}$ is the execution context i.e. an abstraction of guards values via the relational numerical domain and $data \in \A{D}_{Var}$ is an abstraction of the variables (anything that is not a guard) also using the domain $\A{D}$. We separate abstractions over guard variables added by the transformation to GCL and original program variables as there need not be any relationships between guard and regular variables.

\input{abs-transformers}

\paragraph{Correlating Abstract Semantics} \deflabel{CorrelatingAbstractSemantics}
\tabref{AbsTrans} describe the abstract transformers. The table shows the effect of each statement on a given abstract state $\A{\sigma} = l_{\times} \mapsto S$. The abstract transformers are defined using the abstract transformers of the underlying abstract domain $\A{D}$.

We assume that any program P can be transformed such that it contains only the aforementioned operations (specifically GCL format). We also assume that for $\asemp{g:=e}$ operations, $e$ is a logical operation with binary value.
Next, we define the abstraction function $\alpha : 2^{\Sigma^{*}_{times}} \rightarrow 2^{\A{D} \times \A{D}}$ for a set of concrete traces $T \subseteq \Sigma^{*}_{times}$. As in our domain traces are abstracted together if they share the exact same path, we first define an operation $path : \Sigma^{*}_{times} \rightarrow Lab^{*}$ which returns a sequence of labels for a trace's states i.e. what is the path taken by that trace. We also allow applying $path$ on a set of traces to denote the set of paths resulting by applying the function of each of the traces. Finally: $\alpha(T) \triangleq \{ \sqcup_{path(\pi)=p} \beta(last(\pi)) | p \in path(T) \}$ where $\beta(\C{\sigma}) = \langle \beta_{\A{D}}(\C{\sigma}|_Guard), \beta_{\A{D}}(\C{\sigma}|_{Var}) \rangle$  i.e. applying the the abstraction function of the abstract sub-domain $\beta_{\A{D}}$ on parts of the concrete state applying to $Guards$ and $Vars$ separately. Our abstraction partitions trace prefixes $\pi$ by path and abstracts together the concrete states reached by the prefix - $last(\pi)$, using the sub-domain.

%such that each $rd \in S_{RD}$ will abstract a certain \textbf{path} in the product program. We achieve that by instrumenting each $\sigma_{\times} = last(pre(\pi_{\times}))$ in the collecting semantics $CS(l_{\times})$ with the sequence of branches taken up to $\sigma_{\times}$ in $pre(\pi_{\times})$. This is easily achieved by using \emph{guard} values as they are recorded along the trace and we denote $path(\sigma_{\times})$ as the sequence of branches $b_0,...,b_n$ i.e. guard values ($b_i = <g,{T/F}>$), that led up to $\sigma_{\times}$. Therefore we define for every path $p_i$ in the product program the group of concrete correlating states that exist at the end of that path denoted $\Sigma_{\times}^{p_i} \triangleq \{ \sigma_{\times} | path(\sigma_{\times}) = p_i \}$. Finally we define the abstract state itself as $\C{\sigma_{\times}} \triangleq { rd | rd = ABS_{RD}(\Sigma_{\times}^{p_i}) \wedge p_i is a path in P \times P)}$. For example, the abstraction of \figref{MatchingProblemExamplePrograms}'s product program collecting semantics at labels $(lab,lab')$ will first collect together all trace prefixes that iterate the loop 0 times: $\Sigma_{\times}^{p_0} = \{  (x=0,i=0,x'=0,i'=0), (x=1,i=0,x'=1,i'=0), (x=2,i=0,x'=2,i'=0), ... \}$ and abstract them using the relational sub-domain to get $rd_{0} = \{x=x',i=i'=0\}$ which correctly expresses the fact that equivalence is kept in case none of the loops iterate. The next path to be abstracted would be where both loops iterate once i.e. $p_1 = <g,F>,<g',F>$ which also maintains equivalence and will be abstracted as $rd_{1} = \{x=x',i=i'=1, x \geq 1\}$. The next path however, which iterates the $P'$ loop twice but only once for the $P$ loop, $p_2 = <g,F>,<g',F>,<g,T>,<g',F>$ will not maintain equivalence as it will abstract $\Sigma_{\times}^{p_2} = \{  (x=1,i=1,x'=1,i'=2), (x=2,i=2,x'=2,i'=2), (x=3,i=2,x'=3,i'=2), ... \}$ as $rd_{2} = \{x=x',2 \leq i \geq 1, i'=2\}$. We mention that the abstract $rd$ ignores the separation of concrete states of $P$ and $P'$ and abstracts both variable data together. In fact, the ability to maintain direct relationships between the two sets of variables (and specifically those matched by $VC$) is crucial for maintaining equivalence.

Every path in the product program will be represented by a single sub-state of the sub-domain. As a result, all \textbf{traces prefixes} that follow the same path to $l_{\times}$ will be abstracted into a single sub-state of the underlying domain. This abstraction fits semantics differencing well, as inputs that follow the same path display the same behavior and will usually either keep or break equivalence together, allowing us to separate them from other behaviors (it is possible for a path to display both behaviors as in \figref{PathProblemExamplePrograms} and we will discuss how we are able to manipulate the abstract state and separate equivalent behaviors from ones that offend equivalence). Another issue to be addressed is the fact that our state is still potentially unbound as there may be an infinite number of paths in the program (due to loops).

%\paragraph{Computing Abstract State with Our Analysis} \deflabel{ComputingAbstractState}
%We compute the correlating abstract state at each label $\C{\sigma_{\times}}$ by using means of abstract interpretation and program analysis. We interpret our correlating program (described in \secref{CorrelatingProgram}) which is a semantic preserving reduction over the much more arbitrary product program, using a standard fixed-point analysis algorithm, and apply interpreted operations on the set of sub-states of the current state $S_{RD}$. Our initial state explicitly assumes equality on all input variables (by adding a $v=v'$ constraint for every input variable $v$ where $v'=VC(v)$) to allow for sound checking of equivalence. This also allows for pruning of unfeasible paths where inputs diverge\COMMENT{ (though we may still interpret some as feasible due to incompleteness of program operations representation, for example bitwise operations)}. To adhere to the representation of traces in the abstract state, our join operation is in fact set union, thus indeed every prefix that reaches a certain program label will be awarded its own $rd$. Let us explicitly define the operations of the domain in our analysis:
%\begin{itemize}
%\item $S^{RD}_1 \sqsubseteq S^{RD}_2 \Longleftrightarrow \forall rd_1 \in G_1 \exists rd_2 \in G_2 : rd_1 \sqsubseteq_{RD} rd_2$
%\item $S^{RD}_1 \sqcap S^{RD}_2 \equiv { rd_1 \sqcap_{RD} rc_2 | rd_1 \in G_1 \wedge rd_2 \in G_2}$
%\item $S^{RD}_1 \sqcup S^{RD}_2 \equiv S^{RD}_1 \cup S^{RD}_2$
%\end{itemize}
%Next we define two more operations: Canonization (denoted $\odot$) - which allows for minimization of state size according to equivalence criteria and Widening (denoted $\nabla$) - which allows reaching a fixed-point when handling loops.

%\COMMENT{One advantage of our correlating domain over using two separate domains, is the ability to preserve equivalence in the face of non-linear operations - this argument may be too thin to include.}

\input{singlepath-code}

\paragraph{Partitioning}
Performing analysis with the powerset domain does not scale as the number of paths in the correlated program may be exponential. We must allow for reduction of state $\A{\sigma} = l_{\times} \mapsto S$ with acceptable loss of precision. This reduction via partitioning can be achieved by joining the abstract sub-states in $S$ (using the standard precision losing join of the sub-domain) but to perform this we must first answer the following: (i) which of the sub-states shall be joined together and (ii) at which program locations should the partitioning occur. A trivial partitioning strategy is simply reverting back to the sub-domain by applying the join on all sub-states which may result in unacceptable precision loss as exemplified in \figref{SignCorrelating}. However, by taking a closer look at the final state of the same example:
\\
\begin{tabular}{c}
$\A{\sigma}(fin)$ = [
\\
$\langle (g1=1,g2'=0,\equiv_{g1}),(sgn=1,\equiv_{x,sgn}) \rangle$,
\\
$\langle (g1=0,g2'=0,\equiv_{g1}), (x<0,sgn=-1,\equiv_{x,sgn}) \rangle$,
\\
$\langle (g1=0,g2'=1,\equiv_{g1}),(x=0,sgn=0,sgn'=1,\equiv_{x}) \rangle$
\\
]
\end{tabular}
\\
One may observe that were we to join the two sub-states that maintain equivalence on $\{x,sgn,g1\}$, it would result in an acceptable loss of precision (of losing the $x$ related constraints). This is achieved by partitioning sub-states according to the set of variables which they preserve equivalence for. This bounds the state size at $2^{|V|}$, where $V$ is the set of correlating variables we wish to track. 
As mentioned, another key factor in preserving equivalence and maintaining precision is the program location at which the partitioning occurs. The first possibility, which is somewhat symmetric to the first proposed partitioning strategy, is to partition at every join point i.e. after every branch converges. A quick look at \figref{SignCorrelating}'s state after processing the first guarded instruction \scode{if (G1) sgn = -1;}, i.e (we ignored $g2'$ effect at this point for brevity):
\\
\begin{tabular}{c}
$\A{\sigma}$ = [ 
\\
$\langle (g1=0,\equiv_{g1}),(x \geq 0,\equiv_{x,sgn}) \rangle$,
\\
$\langle (g1=1,\equiv_{g1}),(x < 0,sgn' = -1, \equiv_{x}) \rangle$
\\
\end{tabular}
\\
suggests that partitioning at join points will perform badly in many scenarios, specifically here as we will lose all data regarding $sgn$. However if we could delay the partitioning to a point where the two programs "converge" (after the following \scode{if (G1') sgn' = -1;} line), we will get a more precise temporary result which preserves equivalence. Therefore we define another partitioning points, which are defined during the correlating program construction process described in \secref{Correlating}, and are basically locations where the two (guarded) programs have syntactically converged (we found two lines that are syntactically equal, sans tagging). Another possible location for differencing are our \emph{differencing points}. Partitioning at these locations is essentially more precise than at correlation points. We remind that diff-points are product program locations where both programs conceptually converge as they are about to emit output i.e. both programs have finished "preparing" the next portion of output therefore, if equivalence exists - it must exist now, therefore this is a prime candidate for a partitioning point. \TODO{Our evaluation includes applying each of our strategies along with each of the points. Intuitively, the results should range from least precise using the <Join-All,At-Join> strategy and point to most precise in the <Join-Equiv,At-Diff> scenario and this is indeed the case as we show in \secref{Evaluation} (not taking into account the no-partitioning scenario which is naturally most precise).}


%We can see from our motivating example that it is not feasible to allow our correlating domain to keep diverging and double in size with every conditional as it will exponentially blow up the analysis run-time and memory. Instead, we employ an equivalence conserving canonization technique such that at every canonization point we will partition the sub-states according to the set of variables to which they hold equivalence for and join these all together into one abstract, using the sub-domain lossy join. This bounds the number of abstracts in the state to $2^{|V|}$ for variables correlated $VC$. This fine grained equivalence checking is successful in telling apart paths that hold equality for none, some or all of the variables. For instance in \figref{MatchingProblemExamplePrograms}, our canonization will tell apart the sub-state that hold equivalence for all variables $\{i=i'=x=x'=0\}$ from the rest that hold equivalence for $x$ alone and join them all together into the $\{x=x',i \leq x, i' \leq 2x'\}$ state. The fact that we did not lose equivalence altogether is beneficial as we are able to report that the input variable $x$ did not diverge which may be of use in case \scode{foo} had used $x$ further down the road.

\input{loop-correlating2}

\paragraph{Widening}
In order for our analysis to handle loops we require a means for reaching a fixed point. As our analysis advances over a loop and state is transformed, it may keep changing and never converge unless we apply the widening operator to further over-approximate the looping state and arrive at a fixed point. We have the widening operator of our sub-domain at our disposable, but again we are faced with the question of how we apply this operator, i.e. which pairs of sub-states $\langle ctx , data \rangle$ from $\A{\sigma}$ should be widened with which. A first viable strategy, similar to the first partitioning strategy, is to perform an overall join operation on all pairs which will result in a single pair of sub-states and then simply apply the widening to this sub-state using the sub-domain's $\nabla$ operator. If we examine applying this strategy to $sum \bowtie sum$ from \figref{LoopCorrelatingExample}, we see that it will successfully arrive at a fixed point that also maintains equivalence as all sub-states maintain equivalence at loop back-edges. Now let us try applying the strategy to the more complex $sum \bowtie sum'$ as seen in \figref{LoopCorrelatingExample}. First we mention that as $sum'$ introduces a return statement under the $len > max$ condition, the example shows an extra $r'$ guard for representing a return (this exists in all GCL programs but we omitted it so far for brevity). While analyzing, once we pass that first conditional, our state is split to reflect the return effect:
\\
\begin{tabular}{c}
$\A{\sigma}$ = [
\\
$c_1 = \langle$ (r' = 1),(len = len' > max, return\_value' = -1, result = result' = 0) $\rangle$
\\
$c_2 = \langle$ (r' = 0),(len = len' < max, result = result' = 0) $\rangle$
\\
]
\end{tabular}
\\
As we further advance into the loop, $c_2$ will maintain equivalence but $c_1$ will continue to update the part of the state regarding un-tagged variables  (since $r'=1$ in $c_1$ and it will not consider any of the commands guarded by $r'$), specifically it will change $result$ continuously, preventing the analysis from reaching fixed point. We would require widening here but using the naive strategy of a complete join will result in aggressive loss of precision, specifically losing all information regarding $result$. The problem originates from the fact that prior to widening, we joined sub-states which adhere to two different loop behaviors: one where both $sum$ and $sum'$ loop together (that originated form $len < max$) and the other where $sum'$ has existed but $sum$ continues to loop ($len \geq max$). Ideally, we would like to match these two behaviors and widen them accordingly. We devised a widening strategy that allows to do this as it basically matches sub-states that adhere to the same behavior, or loop-paths. We do this by using \emph{guards} for the matching. If two sub-states agree on their set of guards, it means they represent the same loop path and can be widened as the latter originated from the former (widening operates on subsequent iterations). In our example, using this strategy will allow the correct matching of states after consequent $k, k+1$ loop iterations:
\\
\begin{tabular}{c}
$\A{\sigma}_{k}$ = [
\\
$c_1 = \langle$ (r' = 1,g=1,g'=0),
\\
(len = len' > max, return\_value' = -1,
 result' = 0,result = $\Sigma_{i=0}^{k} arr[i]) \rangle$
\\
$c_2 = \langle$ (r' = 0,g=1,g'=1),
\\
(len = len' < max, result = result' = $\Sigma_{i=0}^{k} arr[i]) \rangle$
\\
]
\end{tabular}
\\
And:
\\
\begin{tabular}{c}
$\A{\sigma}_{k+1}$ = [
\\
$c_1 = \langle$ (r' = 1,g=1,g'=0),
\\
(len = len' > max, return\_value' = -1, 
 result' = 0,result = $\Sigma_{i=0}^{k+1} arr[i]) \rangle$
\\
$c_2 = \langle$ (r' = 0,g=1,g'=1),
\\
(len = len' < max, result = result' = $\Sigma_{i=0}^{k+1} arr[i]) \rangle$
\\
]
\end{tabular}
\\
As we can identify the states predecessors by simply matching the guards. $c_1$ will be widened for a precise description of the difference shown as $\langle len = len' > max, return\_value' = -1, return\_value' = \top \rangle$.

\subsection{Correlating Abstract State Differencing} \sseclabel{CorrelatingAbstractDiff}
Given a state in our correlating domain, we want to determine whether equivalence is kept and if so under which conditions it is kept (for partial equivalence) or determine there is difference and characterize it. As our state may hold several pairs of sub-states, each holding different equivalence data, we can provide a verbose answer regarding whether equivalence holds. We partition our sub-states according to the set of variables they hold equivalence for and report the state for each equivalence partition class. Since we instrument our correlating program to preserve initial input values, for some of these states we will also be able to report input constraints thus informing the user of the input ranges that maintain equivalence. In the cases where equivalence could not be proved, we report the offending states and apply a differencing algorithm for extraction of the delta. \figref{PathProblemExamplePrograms} shows an example of where our analysis is unable to prove equivalence (as it is sound), although part of the state does maintain equivalence (specifically for $x=0$). This is due to the abstraction being to coarse. We describe an algorithm that given a sub-state $d \in \A{D}$, computes the differentiating part of the sub-state (where correlated variables disagree on values) by splitting it into parts according to equivalence. This is done by treating the relational constraints in our domain as geometrical objects and formulating delta based on that.

\paragraph{Correlating Abstract State Delta} \deflabel{CorrelatingAbstractStateDelta}
Given a sub-state $d$ and a correspondence $VC$, the correlating state delta $\triangle_{A}(d)$, computes abstract state differentiation over $d$. The result is an abstract state $\sqsubseteq rd$ approximating all concrete values for variables correlated by $VC$, that differ between $P$ and $P'$. Formally, the delta is simply the abstraction of the concrete trace deltas $\alpha(\cup_{path}\triangle_{T}^{+}), \alpha(\cup_{path}\triangle_{T}^{-})$ where deltas are grouped together by path and then abstracted. But it is not clear as to how we compute this set differencing on the correlating abstraction. Instead, we consider the geometric representation of the domain and applied operations there for the extraction of delta, as following:
\begin{enumerate}
\item $d_{\equiv}$ is a state abstracting the concrete states shared by the original and patched program. It is achieved by computing: $d_{\equiv} \triangleq d|_{V=V'} \equiv d \sqcap \bigwedge\{ v = v' | VC(v) = v'\}$.
\item $\overline{d_{\equiv}}$ is the negated state i.e. $\A{D} \setminus d_{\equiv}$ and it is computed by negating $d_{\equiv}$ (as mentioned before, all logical operations, including negation, are defined on our representation of an abstract state).
\item Eventually: $\triangle_{A}(d) \triangleq d \sqcap \overline{d_{\equiv}}$ abstracts all states in $P \times P'$ that where correlated variables values do not match.
\item $\triangle_{A}(d)^{+} = \triangle_{A}(d)|_{V'}$ is a projection of the differentiation to display values of $P'$ alone i.e. "added values".
\item $\triangle_{A}(d)^{-} = \triangle_{A}(d)|_{V}$ is a projection of the differentiation to display values of $P$ alone i.e. "removed values".
\end{enumerate}
Applying the algorithm on \figref{PathProblemExamplePrograms}'s $P$ and $P'$ where $rd = \{ retVal' = 2retVal \}$ will result in the following:
\begin{enumerate}
\item $d_{\equiv} = \{ retVal' = 0, retVal = 0 \}$.
\item $\overline{d_{\equiv}} = [ \{ retVal' > 0 \}, \{ retVal' < 0 \}, \{ retVal > 0 \}, \{ retVal < 0 \} ]$
\item $\triangle_{A}(d)  = [ \{ retVal' = 2retval, retVal' > 0 \}, \{ retVal' = 2retval, retVal' < 0 \}, \{ retVal' = 2retval, retVal > 0 \}, \{ retVal' = 2retval, retVal < 0 \} ]$
\item $\triangle_{A}(d)^{+} = [ \{ retVal' > 0 \}, \{ retVal' < 0 \} ]$
\item $\triangle_{A}(d)^{-} = [\{ retVal > 0 \}, \{ retVal < 0 \}]$
\end{enumerate}
We see that displaying the result in the form of projections is ill-advised as in some states differentiation data is represented by relationships on correlated variables alone, thus projecting will lose all data and we will be left with a less informative result. A geometrical representation of $\triangle_{A}$ calculation can be seen in \figref{Delta}.

\begin{figure}
\imagetop{
%\includegraphics[width=3.0in,clip=true,trim = 100pt 100pt 300pt 300pt]{figures/delta}
}
\caption{Delta computation geometrical representation.}\figlabel{Delta}
\end{figure}

%\input{diff-algo}

From this point forward any mention of 'delta' (denoted $\triangle$) will refer to the correlating abstract state delta (denoted $\triangle_{A})$. We claim that $\triangle$ is a correct abstraction for the concrete state delta which allows for a scalable representation of difference we aim to capture.
