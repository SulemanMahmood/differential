\section{Evaluation}\label{Se:Evaluation}
%We mainly tested our tool on the GNU core utilities, differencing versions 6.10 and 6.11. This benchmark included 40 patches where most of the patches (35) were a one-line patch aimed at updating the version information string in the code. Our analysis easily showed equivalence for these programs. About 10 of these patches included actual changes to numerical variables and we were able to precisely describe the difference. We also tested our tool on a few handpicked patches taken from the Linux kernel and the Mozilla Firefox web browser.

%We implemented a union compiler named \emph{ucc} which creates union programs from any two C programs as well as a differencing oriented dataflow analysis solver for analyzing union programs, both tools use the LLVM and CLang compiler infrastructure. We analyze C code directly thus benefiting from a low number of variables as there are no temporary values as there might appear in an intermediate representation. We also benefit from our delta being computed over original variables. As mentioned in \secref{Union}, we normalize the input programs before unifying them for a simpler analysis.

%Analysis of some of our benchmarks required the use of widening. We applied a basic widening strategy which widens all cfg blocks once reaching a certain threshold. All of our experiments were conducted running on a Intel(R) Core-i7(TM) processor with 4GB.

\subsection{Results}

%\input{results-tab}

%\tabref{Results} summarizes the results of our analysis. The columns indicate the benchmark name and description, lines of code for the analyzed program, the number of lines added and removed by the patch, the number of diff-points generated, the numerical domain used, and the number of differences found in the analysis (i.e. number of diff-points where $\triangle \neq \varnothing$). In our benchmarks, we focused on computing intra-procedural difference between the two versions of procedures. Procedure calls presented difficulty as they potentially change global variables and local variables through pointers. We overcame this by either (i) assuming equivalence (alone) once we encounter a call to a procedure we already established as equivalent or (ii) warn that all results regarding variables touched by the procedure is un-sound. \TODO{In the majority of our benchmarks we identified calls only to library and system procedures thus we could omit their effect as they do not change variables beyond those given as parameter or those being assigned the return value.} All differences reported describe, in constraints over variables, an existing delta at that program point.

\TODO{we are cheating here since DIZY doesn't deduce array lengths, but it probably can}
\begin{figure*}
\centering
\begin{tabular}{cc}
\begin{lstlisting}
size_t rpc_uaddr2sockaddr (const size_t uaddr_len) {
  char buf[ RPCBIND_MAXUADDRLEN ];
    ...
  if ( uaddr_len > sizeof ( buf )) 
    return 0;
    ...
  buf [ uaddr_len ] = '\n';
  buf [ uaddr_len + 1] = '\0';
    ...
}
(*@ \vspace{0.6in} @*)
\end{lstlisting}
\hspace{1.0in}
&
\begin{lstlisting}
size_t rpc_uaddr2sockaddr (const size_t uaddr_len) {
  char buf[ RPCBIND_MAXUADDRLEN ];
    ...
  if ( uaddr_len > sizeof ( buf ) - 2)
    return 0;
    ...
  buf [ uaddr_len ] = '\n';
  buf [ uaddr_len + 1] = '\0';
    ...
}
\end{lstlisting}
\\
coreutils pr.c v6.10 & coreutils pr.c v6.11
\end{tabular}
\caption{Original and patched version of coreutils \scode{pr.c}'s \scode{char\_to\_clump} procedure}
\figlabel{PrExample}
\end{figure*}

\paragraph{Capturing complex delta}
\figref{PrExample} depicts a patch made to \scode{char\_to\_clump} function in version 6.11. The patch replacing the execution of the line \scode{input\_position += width;}, which originally executed unconditionally, with a conditional structure that in the new version, allows the line to execute only under certain complex conditions. Since the variables handled in this patch (the global \scode{input\_position} and return value \scode{chars}) emit output, describing how their values changed and under which terms is important, especially as the patch cannot be easily parsed by a programmer to understand its meaning. Our analysis produces the following description for the differencing point at the return point:
\begin{lstlisting}
<-------------------
State with diff (return value, chars, input_position):
chars' = 0;
input_position = width;
input_position < 0;
input_position' = 0;
------------------->
<-------------------
State with diff (input_position):
input_position' = 0;
input_position < width;
width < 0;
------------------->
<-------------------
State with diff (input_position):
input_position' = 0;
input_position > width;
input_position <= 0; }
------------------->
\end{lstlisting}
The result convey the difference in the output variable values alongside some of conditions under which the difference occurs. The result is composed of three sub-states featuring difference (the offending variables appear before each sub-state) and adhere to two added paths in the patched program. The first sub-state belongs to the first branch in the added conditional: the difference is comprised of (i) the new value of \scode{input\_position} is 0 as opposed to it being \scode{width} in the former version (the analysis took the \scode{input\_position += width;} line into account and incorporated knowing that $input\_position = 0$ from the branch condition). The analysis also deduced that the old \scode{input\_position} is negative under the same input as the branch condition dictates that \scode{width} is negative. (ii) \scode{chars} in the new program is 0 under this path. The two other sub-states adhere to the second added path in the conditional and track a difference for \scode{input\_position} alone, basically stating that \scode{input\_position} under this path used to assume values in ranges $[-\inf,width]$ and $[width,0]$ but now is simply 0. The splitting of this path into two cases is a result of expressing the non-convex $input\_position \neq 0$ condition from the first branch conditional using two sub-states. Running the analysis again while saving the initial values of variables and parameters will produce an even more precise result as following:
\begin{lstlisting}
<-------------------
State with diff (return value, chars, input_position):
input_position_0 = 0;
chars' = 0;
input_position = width;
input_position < 0;
input_position' = 0;
------------------->
<-------------------
State with diff (input_position):
input_position_0 < -width;
input_position_0 < 0;
input_position' = 0;
input_position < width;
width < 0;
------------------->
<-------------------
State with diff (input_position):
input_position_0 < -width;
input_position_0 > 0;
input_position' = 0;
input_position > width;
input_position <= 0;
------------------->
\end{lstlisting}
This result describes constraints on the procedure's input under which the difference exist. Another product of the analysis, which we do not show here, are sub-states describing paths which the patch did not affect.

\begin{figure*}
\centering
\begin{tabular}{cc}
\begin{lstlisting}
int input_position;

bool char_to_clump(char c) {
  int width;
    ...
  input_position += width;
    ...
  return chars;
}
(*@ \vspace{0.6in} @*)
\end{lstlisting}
\hspace{1.0in}
&
\begin{lstlisting}
int input_position;

bool char_to_clump'(char c) {
  int width;
    ...
  if (width < 0 && input_position == 0) {
      chars = 0;
      input_position = 0;
  } else if (width < 0 && input_position <= -width) {
    input_position = 0;
  } else {
    input_position += width;
  }
    ...
  return chars;
}
\end{lstlisting}
\\
coreutils pr.c v6.10 & coreutils pr.c v6.11
\end{tabular}
\caption{Original and patched version of coreutils \scode{pr.c}'s \scode{char\_to\_clump} procedure}
\figlabel{PrExample}
\end{figure*}

\paragraph{Maintaing Equivalence and Reporting Difference in Loops}
\figref{Md5sumExample} shows part of coreutils md5sum.c \scode{bsd\_split\_3} function that was patched in version version 6.11 to disallow 0-length inputs. Although this patch seems trivial, analyzing it is challenging as it affects the behavior of loops i.e. unbound path lengths. The main challenge in this example, is separating the path where \scode{s\_len} is 0, which results in the loop index \scode{i} ranging within negative values (which result in array access out of bounds fault), from the rest of the behaviors that maintain equivalence, throughout the widening process which is required for the analysis to reach a fixed point. The result of our analysis is as follows, per differencing point, with the \emph{By-Equiv} canonization strategy:
\begin{lstlisting}
(*@\textbf{$(*)_1$:} @*)
-------------------
State with diff (i):
s_len = 0; 
s_len' = 0;
i <= - 1;
Equivalent state:
s_len' = s_len;
i' = i;
s_len' - 1 >= i';
-------------------
(*@\textbf{$(*)_2$:} @*)
Equivalent state:
s_len' = s_len;
i' = i;
s_len' - 1 >= i';
-------------------
\end{lstlisting}
We can see the analysis successfully reports a difference for the singularity point \scode{s\_len = 0} inside the loop, precisely describing the scenario where \scode{i'} is negative. We can also see the other equivalent state existing within the loop which depicts the results of the widened analysis for all other paths (the $s\_len \neq 0$ constraint is not existing there due to canonization as we will soon show). The differencing sub-state will be omitted once we move past the loop as the $i \leq -1$ constraint will not allow it to exist beyond the loop body (\TODO{we do not account for overflow at this point in our work as ???}) thus we are left with the equivalent state alone after the loop which correctly expresses the fact that the programs are equivalent at this point (since both i's converged at 0). We can see that the result at the second differencing point has lost precision since it does not reflect the \scode{i = 0} constraint. The loss of this constraint is, again, due to canonization as both sub-states that describe exiting the loop and the one describing entering the loop, hold equivalence for all variables and are joined to together and lose the extra constraint information.
\TODO{describe the canonization for the example?}
If we analyze the same example with the \emph{By-Guards} canonization strategy we get:
\begin{lstlisting}
-------------------
(*@\textbf{$(*)_1$:} @*)
State with diff (i):
s_len = 0;
s_len' = 0;
i <= - 1;
Equivalent state:
s_len' = s_len;
i' = i;
s_len' - 1 >= i';
Equivalent state:
s_len' = s_len;
i' = i;
i = 0;
s_len' >= 1;
-------------------
(*@\textbf{$(*)_2$:} @*)
Equivalent state:
s_len' = s_len;
i' = i;
i = 0;
s_len' >= 1;
-------------------
\end{lstlisting}
Which further separates the paths in the program, allowing for a different sub-state for the $i = 0$ and $i \neq 0$ substates (again, the $i \neq 0$ constraints was lost when joining together the $i > 0$ and $i < 0$ states as they both adhere to the same path and hold the same guard values). This extra precision is beneficial, but we still managed to supply a satisfactory result using the more scalable canonization by equivalence technique.

\begin{figure*}
\centering
\begin{tabular}{cc}
\begin{lstlisting}
bool bsd_split_3 (char *s, size_t s_len,...) {
  int i = s_len;
  i--;
  while (i && s[i] != ')') { (*@\textbf{$(*)_1$} @*)
    i--;
  }
  ...
  (*@\textbf{$(*)_2$} @*)
}
(*@ \vspace{0.03in} @*)
\end{lstlisting}
&
\begin{lstlisting}
bool bsd_split_3 (char *s, size_t s_len,...) {
  int i = s_len;
  i--;
  (*@\textbf{if (s\_len == 0) return false;} @*)
  i = s_len - 1;
  while (i && s[i] != ')') { (*@\textbf{$(*)_1$} @*)
    i--;
  }
  ...
  (*@\textbf{$(*)_2$} @*)
}
\end{lstlisting}
\\
coreutils md5sum.c v6.10 & coreutils md5sum.c v6.11
\end{tabular}
\caption{Original and patched version of coreutils \scode{md5sum.c}'s \scode{bsd\_split\_3} procedure}
\figlabel{Md5sumExample}
\end{figure*}

