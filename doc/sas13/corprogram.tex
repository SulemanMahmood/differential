\section{Correlating Program} \seclabel{Correlating}

In this section we will describe how we construct our correlating program $P \bowtie P'$. The process of correlating attempts to find a better interleaving of programs for a more precise differentiation. The building process also instruments $P \bowtie P'$ with the required differencing points $DP$ which allow reporting of difference and finds correlation points $CP$ which define the locations for out partitioning. We also allow a user defined selection of $DP$ and $CP$. We start off with a discussion of differencing points and how the analysis calculates difference

\subsection{Program Correspondence and Differential Points} \sseclabel{DiffPoints}
Selecting the point where $\triangle$ is computed is vital for precision. As mentioned, a natural selection for diff points would be at the endpoints of traces but that loses meaning under the collecting semantics. A possible translation of this notion under the collecting semantics would be to compute delta between \emph{all} the endpoints of the two programs i.e. $DP = \{(fin,fin') | fin \in exit(P), fin' \in exit(P') \}$ somehow differentiating the final states of the programs. This approach is problematic for two reasons:
\begin{enumerate}
\item Comparing all endpoints results in a highly imprecise delta. This is shown by the simple exercise of taking program with 2 endpoints and comparing it with itself.
\item This choice for $DP$ may result in missing key differences between versions. If at some point during the calculation existed a delta that failed reaching the final state - it will be ignored. An interesting example for this is an array index receiving different bounds after a patch (but later overwritten so that it is not propagated to some final state).
\end{enumerate}
Alternatively, the brute force approach where we might attempt to capture more potential diffs by selecting a diff-point after every line, will result in a highly inaccurate result as, for instance in \figref{ProductProgramExample}, many diffs will be reported although there is no difference.
Finally, we must be careful with the selection of $DP$ as it affects the soundness of our analysis: we might miss differences if we did not correctly place diff-points in locations where delta exists.
\TODO{Our approach employs standard syntactic diff algorithm \ref{Diff} for producing the correlation.} \TODO{This selection for $DP$ assures soundness}. The Diff approach works well since two versions of the same software (and especially those that originate from subsequent check-ins to a code repository) are usually similar. Another important factor in the success of the diff is the guarded instruction format for our programs (as defined in \defref{Program}). Transforming both programs to our format helps remove a lot of the "noise" that a patch might introduce yet it is superior to low level intermediate representation as it retains many qualities (such as variable names, conditions, no temporaries, etc.). \TODO{See \appref{Guarded} for examples illustrating said benefits and qualities}. There are alternate ways for creating the correspondence such as \TODO{graph equivalence, etc.}, this could be a subject of future research. \secref{AbstractSem}.


\subsection{Construction of $P \bowtie P'$ }\sseclabel{CorrelatingProgramConstruction}
The idea of a correlating program is similar to that of
self-composition~\cite{BartheDArgenioRezk04,AikenTerauchi05}, but the way in
which statements in the correlating program are combined is carefully designed to
keep the steps of the two programs close to each other. Rather than having
the patched program sequentially composed after the original program, our
correlating program interleaves the two versions. Analysis of the correlating program can then recover equivalence between values of correlated variables even when
equivalence is \emph{temporarily} violated by an update in one version, as
the corresponding update in the other version follows shortly thereafter.

We will generally describe the process of constructing the correlating program. The correlating program is an optimized reduction over $P \times P'$ where not all pairs of $(\sigma,\sigma')$ are considered, but only pairs that result from a controlled execution, where correlating instructions in $P$ and $P'$ will execute adjacently. This will allow for superior precision. 

The input for the correlation process are two program $(P,P)$ in C. The first step involves transforming both programs to a normalized guarded instruction form $(P^{G},P'^{G})$. Next, a vector of \emph{imperative commands} $I$ (and $I'$ respectively) is extracted from each program for the purposes of performing the syntactic diff. An imperative command in our GCL format is defined to be either one of $v := e | goto l | f(...)$ as they effectively change the program state (variable values, excluding guard). Then a syntactical diff~\cite{HuntMcIlroy75} is computed over the vectors $(I,I')$. One of the inputs to the diff process is $VC$ as it is needed to identify correlated variables and the diff comparison will regard commands differing by variable names which are correlated by $VC$ as equal. The result of the last step will be a vector $I_{diff}$ specifying for each command in $I,I'$ whether it an added command in $P'$ (for $I'$) marked $+$, a deleted command from $P$ (for $I$) marked $-$, or a command existing in both versions $=$. This diff determines the order in which the commands will be interleaved in the resulting $P \bowtie P'$ as we will iterate over the result vector $I_{diff}$ and use it to construct the correlating program. We remind that since $I,I'$ are only the imperative commands, we cannot use it directly as $P \bowtie P'$. Instead we will use the imperative commands as markers, specifying which chunk of program from $P$ or $P'$ should be taken next and put in the result. The construction goes as follows: iterate over $I_{diff}$ and for every command $c$ ($c'$) labeled $l_c$ ($l_{c'}$):
\begin{itemize}
\item read $P$ ($P'$) up to label $l_c$ ($l_{c'}$) including into block $B_c$ ($B_c'$)
\item for $B_c'$, tag all variables in the block.
\item emit the block to the output.
\item delete $B_c$ ($B_c'$) from $P$ ($P'$).
\end{itemize}
The construction is now completed. We only add that at the start of the process, we strip $P'$ of its prototype and add declarations for the tagged input variables, initializing them to the untagged version.
As mentioned $CP$ is also a product of the construction, and it's defined using $=$ commands: after two $=$ commands are emitted to the output, we add an instrumentation line, telling the analysis of the correlation point.
Another observation we make, is that the result program is a legal C program, containing the semantics of the two programs and can be run to receive the output of the programs.
 
starts out as (exactly) the older version $P^{G}$ ($P$ after being converted to our guarded instruction form). Afterwards a syntactic diff with $P'$ (also transformed to guarded mode) is computed (the programs are not combined just yet). In fact, this is the point where $DP$ is created as the diff supplies us with the correlation between labels we desire. Then $P'$'s instructions are interleaved into the guarded $P$ while maintaining the correlation found by the diff (matched instructions will appear consequentially). Just before a patched instruction is interleaved into the correlating, all variables that appear in it are tagged, as to make sure that the patched instructions will only affect patched variables. Thus we maintain the semantics of running both programs correctly while achieving a new construct that will allow us to analyze change more easily and precisely. \TODO{\figref{} holds a complete correlating program of the program in \figref{} and it's patched version, a graphic description as a controlled automata is shown in \figref{}}. Note that if we view the general correlating program as a concurrent program, then this optimized program can be viewed as a partial-order reduction applied over the concurrent program. One final observation regarding the correlating program is that it is a legitimate program that can be run to achieve the effect of running both versions. This ability allows us to use dynamic analysis and testing techniques such as fuzzing \ref{} and directed automated testing \ref{} which may produce input that lead to states approximated by $\triangle$.


\subsection{General Product Program} \sseclabel{ProductProgram}
A simple approach for a joint analysis is to construct a product program $P \times P'$ where at every point during the execution we can perform a program step (as defined in \defref{Program}) of either programs. The product program has a duo-state $(\sigma,\sigma')$ and each step updates $(\sigma,\sigma')$ accordingly. The product program can also be seen as a concurrent run $P||P'$ where every interleaving is possible. The product program emphasizes the fact that, as described in~\secref{ConcreteSem}, the notion of $\triangle$ is unclear without an established variable and label correspondence. Choosing the \b{location} where $\triangle$ is checked is a key part of identifying differences. %Consider~\figref{ProductProgramExample}, which presents a product automata of the simple program with itself, we see that even in this trivial program, although it is clear that $\triangle = \emptyset$, checking for difference in any of the non-correlating states will result in a false difference being reported. As this example demonstrates, selecting a correct label correspondence is crucial for a meaningful delta, we will elaborate on our approach for choosing $DP$ in \subref{DiffPoints}.

%\begin{figure}[ht] \figlabel{ProductProgramExample}
%\lstset{numbers=left, language=C, basicstyle=\ttfamily\scriptsize,emph={},emphstyle=\textbf,escapechar=\%}
%\begin{lstlisting}
%void foo() {
%    int x = 0;
%}
%\end{lstlisting}
%\caption{Program $P$}
%\centering
%\includegraphics[scale=1]{figures/product_program_example.png}
%\caption{Product Program $P \times P$}
%\end{figure}



\subsection{Analyzing Correlating Programs}\sseclabel{AnalyzeCorrelating}
Analyzsis of a guarded correlating program has certain caveats.
\begin{figure}[ht]\figlabel{GuardProblemExample}
\lstset{numbers=left, language=C, basicstyle=\ttfamily\scriptsize,emph={},emphstyle=\textbf,escapechar=\%}
\begin{lstlisting}
l:  guard g = (i>0);
    if (g) i--;
    if (g) goto l;
\end{lstlisting}
\caption{example program illustrating guard analysis caveat}
\end{figure}
In order to correctly analyze the program in \figref{GuardProblemExample} we need our analysis to assume $(i>0)$ whenever taking the true branch on the \scode{if (g)} instruction and $(i<=0)$ when taking the false branch. However, since the \scode{i--} instruction invalidates this assumption we would need to update the guard assumption to $(i>-1)$ which would complicate the analysis as we would need to consider updating the guard assumption while widening etc. Our solution simply incorporates the guard's assumption the first time it encounters the guard and allows it to flow to the rest of the nodes. We are not in danger of losing the assumption during the following join as our join employs a partition-by-equivalence strategy and will not join the two states where ${g,i>0}$ and ${\neg{g},i<=0}$.

%\subsection{Instrumented Collecting Semantics Correlating}\label{Se:Naive}
%In this section we say why instrumenting the program with $x \equiv x'$ is cruicial since otherwise we are unable to establish %equality. Take for instance a program where the analysis result will be $ 0 < x < 9 and 0 < x' <9 $...  