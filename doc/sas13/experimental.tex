\section{Evaluation}\seclabel{Evaluation}
We evaluated {\tool} on a number of challenging real world programs where the patches affect numerical variables. As benchmarks, we used several programs from the GNU core utilities (differencing versions 6.9, 6.10 and 6.11), as well as a few handpicked patches taken from the Linux kernel and the Mozilla Firefox web browser.

\subsection{Prototype Implementation}
We implemented a correlating compiler named \sname{CCC} which creates correlating programs from any two C programs. We also implemented a differencing analysis for analyzing correlated programs. Both tools are based on \sname{LLVM} and \sname{Clang} compiler infrastructure. We analyze C code directly since it is more structured, has type information and keeps a low number of variables, as opposed to intermediate representation. We also benefit from our delta being computed over original variables. As mentioned in \secref{Correlating}, we normalize the input programs before unifying them for a simpler analysis. \TODO{Our analysis is intra-procedural and we handle function calls by either modularly proving their equivalence and assuming it once encountered or, in case equivalence could not be proved, by inlining}. Calls to external system functions do not change local state in our examples and thus were ignored. We used the \sname{APRON} abstract numerical domain library and conducted our experiments using several domains including octagon \cite{Mine2006} and polyhedra~\cite{CousotHalbwachs78}. All of our experiments were conducted running on a Intel(R) Core-i7(TM) processor with 4GB.

\subsection{Results}

\input{results-tab}

\tabref{Results} summarizes the results of our analysis. The columns indicate the benchmark name and description, lines of code for the analyzed program, the number of lines added and removed by the patch, the number of diff-points generated, the numerical domain used, and the number of differences found in the analysis (i.e. number of diff-points where $\triangle \neq \varnothing$). In our benchmarks, we focused on computing intra-procedural difference between the two versions of procedures. Procedure calls presented difficulty as they potentially change global variables and local variables through pointers. We overcame this by either (i) assuming equivalence (alone) once we encounter a call to a procedure we already established as equivalent or (ii) warn that all results regarding variables touched by the procedure is un-sound. \TODO{In the majority of our benchmarks we identified calls only to library and system procedures thus we could omit their effect as they do not change variables beyond those given as parameter or those being assigned the return value.} All differences reported describe, in constraints over variables, an existing delta at that program point.

%\para{Non convex delta}
%
%Another example, taken from CVE-2010-1196 advisory regarding Firefox's heap buffer overflow on 64-bit systems is shown in \figref{FirefoxExample} (vulnerable part of the function only). Firefox 3.5 and 3.6 (up to 3.6.4) contain a heap buffer overflow vulnerability which is caused by an integer overflow. Due to the amount of data needed to trigger the vulnerability (> 8GB), this is only exploitable on 64-bit systems. The vulnerable code is found in \scode{/content/base/src/nsGenericDOMDataNode.cpp}
%of the Mozilla code base and was adapted to C for analysis purposes.
%
%\input{code/firefox}
%
%Here, we need to describe a non-convex constraint that leads to difference. Running {\tool} with partitioning produces the result shown in \figref{nsGenericDOMDataNode}~(a) (only the part of the state which breaks equivalence is shown).
%\begin{figure}
%\scriptsize
%\centering
%\begin{tabular}{ccc}
%\begin{tabular}{l}
%$\sigma_1$:
%\\ \hline
%returned' = $true$
%\\
%returned = $false$
%\\
%return value' = NS\_ERROR
%\\ \hline \vspace{0.1in}
%\end{tabular}
%&
%\hspace{0.5in}
%&
%\begin{tabular}{l|l}
%$\sigma_1$:                                         & $\sigma_2$:
%\\ \hline
%returned' = $true$                                  & returned' = $true$
%\\
%returned = $false$                                  & returned = $false$
%\\
%newLength > 536870912                               & newLength > -3758096384
%\\
%                                                    & newLength < 0
%\\
%return value' = NS\_ERROR                           & return value' = NS\_ERROR
%\\ \hline
%\end{tabular}
%\\
%(a)
%&
%&
%(b)
%\end{tabular}
%\caption{Difference for Firefox nsGenericDOMDataNode, (a) with a single polyhedra; (b) set of polyhedra.}\label{Fi:nsGenericDOMDataNode}
%\end{figure}
%
%The difference in state is described correctly as indeed the only change in values for the patch scenario would be the return value and the early return of the patched version. However, we did not preserve the conditional constraints as they are non-convex. Running the same analysis with no partitioning (this is feasible as the procedure does not loop) produces the result shown in \figref{nsGenericDOMDataNode}~(b).
%
%Now we see that the \scode{(unsigned)newLength > (1 << 29)} constraint has been successfully encoded in two offending states, each holding a part of the problematic range.
%
%\para{Capturing complex delta}
%
%\input{code/pr}
%
%\figref{PrExample} shows a patch made to the \scode{char\_to\_clump} function in version 6.11 of coreutils. The patch replacing the execution of the line \scode{input\_position += width}, which originally executed unconditionally, with a conditional structure that in the new version, allows the line to execute only under certain complex conditions. Since the variables handled in this patch (the global \scode{input\_position} and return value \scode{chars}) emit output, describing how their values changed and under which terms is important, especially as the patch cannot be easily parsed by a programmer to understand its meaning. The result of our analysis at the return point is shown in \figref{CharToClump}. These results include information regarding initial values of parameters for improved precision (this is one of {\tool}'s features).
%
%\begin{figure}
%\scriptsize
%\centering
%\begin{tabular}{l|l|l}
%$\sigma_1$:                 & $\sigma_2$:                   & $\sigma_3$:
%\\ \hline
%input\_position${_0}$ = 0     & input\_position${_0}$  < -width & input\_position${_0}$  < -width
%\\
%chars' = 0                & input\_position${_0}$  < 0      & input\_position${_0}$  > 0
%\\
%input\_position = width   & input\_position' = 0        & input\_position' = 0
%\\
%input\_position < 0       & input\_position < width     & input\_position > width
%\\
%input\_position' = 0      & width < 0                   & input\_position <= 0
%\\ \hline
%\end{tabular}
%\caption{Difference for coreutils pr.c \scode{char\_to\_clump}}\label{Fi:CharToClump}
%\end{figure}
%
%The result convey the difference in the output variable values alongside some of conditions under which the difference occurs. The result is composed of three sub-states featuring difference and adhere to two added paths in the patched program. The first sub-state belongs to the first branch in the added conditional: the difference is comprised of (i) the new value of \scode{input\_position} is 0 as opposed to it being \scode{width} in the former version (the analysis took the \scode{input\_position += width} line into account and incorporated knowing that $input\_position = 0$ from the branch condition). The analysis also deduced that the old \scode{input\_position} is negative under the same input as the branch condition dictates that \scode{width} is negative. (ii) \scode{chars} in the new program is 0 under this path. The two other sub-states adhere to the second added path in the conditional and track a difference for \scode{input\_position} alone, basically stating that \scode{input\_position} under this path used to assume values in ranges $[-\infty,width]$ and $[width,0]$ but now is simply 0. The splitting of this path into two cases is a result of expressing the non-convex $input\_position \neq 0$ condition from the first branch conditional using two sub-states. The result also describes constraints on the procedure's input under which the difference exist. Another product of the analysis, which we do not show here, are sub-states describing paths which the patch did not affect.
%
%\para{Maintaining Equivalence and Reporting Difference in Loops}
%\input{code/dse}
%
%\figref{DSEExample} shows two version of the java \scode{logicalValue()} method taken from~\cite{DwyerElbaumPerson08}, adapted to C. This example features semantic preserving refactoring modification (introducing the \scode{elapsed} variable and \scode{THRESHOLD} constant, simplifying a conditional and moving the return statement out of branch block) and one semantic change where $1$ is returned instead of $old$ in case $curr - t < 100$). The challenge in this example is proving equivalence over the loop branch and reporting difference for the negated path. Using a separate analysis, we would have to deduce at the following loop invariant: $val = \Sigma_{i=0}^{data.length}data[i]$ in order to show equivalence. However, as our abstraction focuses on variable relationships and our correlating program allows us to interleave the two loops in lock-step, all our analysis needs to deduce is the $val = val'$ constraint. As we apply widening to converge, the constraint will be kept, allowing us to establish equivalence for the looping path. {\tool} reports the state shown in \figref{logicalValue} state for the exit point of \scode{logicalValue()}. We note that in~\cite{DwyerElbaumPerson08} the example was run  by unrolling 2 steps of the loop.
%
%\begin{figure}
%\scriptsize
%\centering
%\begin{tabular}{l}
%$\sigma_1$:
%\\ \hline
%curr - t < 100
%\\
%return value = old
%\\
%return value' = 1
%\\ \hline
%\end{tabular}
%\caption{Difference for \scode{logicalValue}}\label{Fi:logicalValue}
%\end{figure}
%
%\input{code/md5sum}
%Next we shall explore a different loop scenario where all paths in the programs contain loops and only some of them maintain equivalence. \figref{Md5sumExample} shows part of coreutils md5sum.c \scode{bsd\_split\_3} function that was patched in version version 6.11 to disallow 0-length inputs. Although this patch seems trivial, analyzing it is challenging as it affects the behavior of loops i.e. unbound path lengths. The main challenge in this example, is separating the path where $s\_len$ is 0, which results in the loop index $i$ ranging within negative values (producing an array access out of bounds fault), from the rest of the behaviors that maintain equivalence, throughout the widening process which is required for the analysis to reach a fixed point. The result of our analysis with partitioning is shown in \figref{bsdSplit}~(a) (per differencing points $(*)_{1},(*)_{2}$).
%
%\begin{figure}
%\scriptsize
%\centering
%\begin{tabular}{c}
%\begin{tabular}{l||l}
%\begin{tabular}{l|l}
%\multicolumn{2}{l}{$(*)_1$:}
%\\ \hline
%$\sigma_1$:     & $\sigma_2$ (equivalent):
%\\ \hline
%s\_len = 0      & s\_len' = s\_len
%\\
%s\_len' = 0     & i' = i
%\\
%i $\leq$ -1     & s\_len' - 1 $\geq$ i'
%\\ \hline
%\end{tabular}
%&
%\begin{tabular}{l}
%\multicolumn{1}{l}{$(*)_2$:}
%\\ \hline
%$\sigma_1$ (equivalent):
%\\ \hline
%s\_len' = s\_len
%\\
%i' = i
%\\
%s\_len' - 1 $\geq$ i'
%\\ \hline
%\end{tabular}
%\end{tabular}
%\\ \\ (a) \\
%\begin{tabular}{l||l}
%\begin{tabular}{l|l|l}
%\multicolumn{2}{l}{$(*)_1$:}
%\\ \hline
%$\sigma_1$:     & $\sigma_2$ (equivalent):  & $\sigma_3$ (equivalent):
%\\ \hline
%s\_len = 0      & s\_len' = s\_len          & s\_len' = s\_len
%\\
%s\_len' = 0     & i' = i                    & i = 0
%\\
%i $\leq$ -1     & s\_len' - 1 $\geq$ i'     & s\_len' $\geq$ 1
%\\ \hline
%\end{tabular}
%&
%\begin{tabular}{l}
%\multicolumn{1}{l}{$(*)_2$:}
%\\ \hline
%$\sigma_1$ (equivalent):
%\\ \hline
%s\_len' = s\_len
%\\
%i' = i
%\\
%i = 0
%\\
%s\_len' $\geq$ 1
%\\ \hline
%\end{tabular}
%\end{tabular}
%\\ \\ (b)
%\end{tabular}
%\caption{Difference for \scode{bsd\_split\_3}}\label{Fi:bsdSplit}
%\end{figure}
%
%
%We can see the analysis successfully reports a difference for the singularity point $s\_len = 0$ inside the loop, precisely describing the scenario where $i'$ is negative. We can also see the other equivalent state existing within the loop which depicts the results of the widened analysis for all other paths (the $s\_len \neq 0$ constraint is not existing there due to partitioning as we will soon show). The differencing sub-state will be omitted once we move past the loop as the $i \leq -1$ constraint will not allow it to exist beyond the loop body \COMMENT{(we do not account for overflow at this point in our work as ???)} thus we are left with the equivalent state alone after the loop which correctly expresses the fact that the programs are equivalent at this point (since both i's converged at 0). We can see that the result at the second differencing point has lost precision since it does not reflect the $i = 0$ constraint. The loss of this constraint is, again, due to partitioning as both sub-states that describe exiting the loop and the one describing entering the loop, hold equivalence for all variables and are joined to together and lose the extra constraint information.
%\COMMENT{? describe the canonization for the example}
%If we analyze the same example with no partitioning we get the result of \figref{bsdSplit}~(b).
%
%Which further separates the paths in the program, allowing for a different sub-state for the $i = 0$ and $i \neq 0$ substates (again, the $i \neq 0$ constraints was lost when joining together the $i > 0$ and $i < 0$ states as they both adhere to the same path and hold the same guard values). This extra precision is beneficial, but we still managed to supply a satisfactory result using the more scalable partitioning by equivalence technique.

\subsection{Producing Exploits/Regression Tests}

