\section{Future Work}\seclabel{Future}

In this section we will first outline the different aspects of the differential analysis problem and discuss questions and research directions which derive from them. Second, we will propose a time line for exploring these directions throughout the research. As the problem of differential analysis is vast, we do not plan to explore all proposed directions immediately (some will not appear in the research plan and will be considered as the research progresses).

\subsection{Problem Dimensions}

\subsubsection{Program Correlation}

The problem of correlating executions of different programs for differentiation is only partially addressed in our work so far. We chose to use a standard semantics over a correlating program in order to leverage existing analysis techniques (that were adapted to maintain information about variable correlations). We constructed our correlating program using a simple syntactic diff algorithm over imperative commands of normalized programs. This method performs well on many examples, but may still produce a result that defies successful analysis, when encountered with complex language features or more drastic program changes. 

\paragraph{Guarded Commands Format}
The process of creating a correlating program entails the transformation of C programs into a guarded command format s.t. programs may be interleaved more easily. This process is not trivial and must be carefully executed to preserve semantics. As there exists no production grade tool that performs this C-to-C transformation, it was implemented as a part of the research. However, this transformation is not yet complete as it does not handle all of the complex C program features. As this transformation can be useful for various applications (as it allows program interleaving), and specifically our research, we consider further extending and completing it towards using it as a building block for other research.

\paragraph{Correlating Program Caveats}
A more careful examination of the correlating program, reveals that branching may break program semantics. By observing any of the correlating programs examples that contain a branching \scode{goto} command, one sees that if the branch destination of one program conflicts with that of the second program, the second program semantics will change (and vice versa). This has not been a problem for the set of examples we handles so far, but needs adjustment if we strive to handle more complex, larger examples. Correct composition of programs requires instrumenting the programs with an explicit program counter, and executing instructions according to the value of the counter. This can produce a more dynamic composition that allows more control over which program advances at each step. \COMMENT{An example of such composition for the program from \figref{SignExample} is shown in \figref{SignCorrelating2}.

\input{code/sign-correlating2}
}

\paragraph{Program Graph Correlation}
Our method for composing programs so far has used the textual representation sequential order of commands as a basis for composition. We took the vectors of (guarded) commands from both programs and tried to match it using a syntactic diff. There is much potential in applying other techniques for finding this matching. Previous work addressing syntactical methods for program equivalence using graph representation~\cite{Horwitz89,Horwitz90} can be used to find a matching for differentiation. This matching, unlike ours, considers all sort of instructions in the program (i.e. branch conditionals, etc. as well as imperative commands).

\paragraph{Correlation Refinement} The correlating program is an input for the analysis process and effectively determines the order in which each of the programs will execute alternately. We raise the question: does this "scheduling" need be predetermined? The analysis can defy the constant interleaving supplied by the correlating program and choose to execute more commands of one program instead of alternating to the other program to try and explore a better result. The immediate criteria for defining this "better" result would be equivalence, i.e. the analysis would choose to advance further in the execution of one program, until it reached a more equivalent abstract state (more variables now maintain equivalence). An example where such a techniques is useful can be seen in \figref{SeqExample}. 

\input{code/seq}

Trying to find a textual correlation between these two version will fail, and existing approaches will not be able to capture the fact that these version only differ slightly, and only one extra output will be emitted (for the case where $out\_of\_range$ is true and $print\_extra\_number$ is true). In this example, if we allow the analysis to choose the order of alternation between each programs, until it reaches a point of output (this is an equivalence-in-output criteria), it will produce a result stating that the programs are equivalence up to the point where the extra number is printed.

This is a sort of equivalence-guided correlation refinement analysis. We note that equivalence is only one option for guiding the correlation. To practically produce such an analysis, we will either need to extend the correlating program to the format discussed in the previous paragraph or use a dual analysis over two programs, as discussed in \secref{ExtendedAnalysis}. 

\subsubsection{Definition of Difference}

\paragraph{Extending the Notion of Difference}
Previous work regarding semantic differencing~\cite{DwyerElbaumPerson08, GodlinStrichman09, EnglerRamos11, HawblitzelKawaguchiLahiriRebelo12} define program difference as difference between outputs in final state. This notion of difference may be insufficient, as observable behavioral changes may appear before the program terminates (as explained in \secref{OverviewDiffDef}. We explore extending the notion of difference towards (i) array access indexes (ii) output functions (iii) assertion violations. This means that our analysis will compute difference at these locations - specifically for variables which values affect the access index/output value/assertion correctness - as well as the final state. This task is not trivial for all programs, as difference program versions can emit a difference number of output, or access different arrays. These scenarios require further study.

\paragraph{Specification Guided Differential Analysis}
Proposing to compute program difference at assertion locations introduces specifications into the domain of differential analysis. One may wish to ignore output equivalence and concentrate on the question of how does patching a certain program affects its \emph{specification}? This has the potential to be a simpler problem and a lower hanging fruit as we have seen no previous work addressing this particular question. One can further leverage the program specification, by assuming it as part of the analysis process for a sort of "delta verification" technique which relies on the hypothesis that the previous version holds up to its specification, and tries to verify that the patched version does so as well.


\subsubsection{Extending Existing Analysis}\seclabel{ExtendedAnalysis}

So far we have explored using only intra-procedural static analysis over a correlated program with numerical abstract domains. This can be vastly extended as follows:

\paragraph{Dual Program Analysis}
As mentioned, performing the analysis over the correlating program has disadvantages as it requires a complex canonization and composition of programs. We consider porting our analysis framework to work over two program CFGs. This will alleviate the need for performing complex transformation and composition and will also allow us to implement correlation refinement as we can independently choose on which of the program graphs we wish to advance (conceptually, this could also be performed on the correlated program but with much less ease). This will also allow us to easily use graph correlation techniques for choosing the order of advancement over the two programs. The disadvantage of this method is that it does not create a single, runnable correlating program (that can by used by other techniques as described in \seclabel{OtherAnalysis}).

\paragraph{Inter-procedural Analysis} 
We aim to achieve a better inter-procedural analysis technique as we now rely on modular analysis of function calls to prove equivalence or inlining in case equivalence cannot be proven.

\paragraph{Floats, Pointers, Arrays and Heap Domains}
Further research is required for adding abstract domains to support representation of other variable types including floating point, pointers, arrays and complex heap data structures.

\COMMENT{
\paragraph{Analyzing Concurrent Programs}
}

\subsubsection{Analysis Techniques}\seclabel{OtherAnalysis}
We do not limit ourselves purely to static methods of abstract interpretation. We believe the the experience and techniques gained in our research so far can be used to apply other analysis techniques successfully.

\paragraph{Dynamic Analysis.} We plan to employ dynamic analysis techniques,
    for finding differences by running both versions of the program with
    the same input and check for equivalence between output states. This
    method is lacking as it is not able to detect differences that occur
    during execution such as array accesses, pointer de-referencing etc. Using our \emph{correlating program} however, we
    can detect these differences as we can compare values at differencing
    points.

\paragraph{Symbolic Execution.} This method has become very popular in
    achieving better test coverage for
    programs~\cite{CadarDunbarEngler08} and there have been attempts at
    employing this method for comparing program
    versions~\cite{EnglerRamos11, HawblitzelKawaguchiLahiriRebelo12,DwyerElbaumPerson08}.
    Although this method is not sound, it offers results with zero false
    positives. We intend to explore the use of symbolic execution methods
    for differencing, starting by using our correlating program as an
    input to existing symbolic execution tools. This will allow producing actual input values which generate different outputs in the compared programs.

\paragraph{Concolic Execution.} A method combining testing (\textbf{conc}rete)
    and symbolic execution ((symbo\textbf{lic}) which is more scalable as
    only part of the execution is symbolically represented and the rest
    runs with concrete values. An interesting question is how can we
    direct this method towards focusing on program differences (using the
    correlating program) and getting more differencing inputs.

\paragraph{Statically Directed Symbolic Execution.} One of the pitfalls of
    symbolic execution methods is coverage. Due to an exponential number
    of paths, pruning techniques are required to achieve better coverage.
    We intend to the results from our static analysis towards limiting
    variable ranges and number of paths to be explored for finding
    difference. We believe that using the analysis data (for instance to
    ignore parts of the programs that were proven equivalent) can
    immensely improve performance.

\subsubsection{Future Evaluation}

Finally we will discuss the method we plan on evaluating our work with.
\begin{enumerate}
\item \textbf{Contrived Challenge Programs}: We will test on a set of short program, each presenting a different challenge for differential analysis, including: variable and location correlation, false differences, false equivalence, loops, etc. to evaluate the advantages and pitfalls of each technique.
\item \textbf{GNU Coreutils}: We will test on the coreutils benchmark of medium length C programs. These will give us a clue as to how we perform on real world code.
\item \textbf{Patch Survey}: We will perform a survey of patching to determine how patches look in large scale programs (OS, browsers, etc.) and which features they include and evaluate how our tool will perform there.
\end{enumerate}

\COMMENT{
\subsubsection{Applications}

\begin{enumerate}
\item \textbf{Producing Differencing Inputs}
\end{enumerate}
}

\subsection{Research Timeline}
The following are the immediate research topics we plan to address. We will consider other topics as mentioned in \secref{Intro} as our research advances and according to the results of our immediate plans.

\begin{enumerate}
\item Better our existing tool to achieve compelling results on a larger set of real numerical programs. Our tool will be able to process large code examples and produce a precise and useful delta when such exists or prove no delta exists. -- 2 months.
\item Explore applying dynamic analysis methods such as fuzz testing, concolic and symbolic execution to correlating programs in order to evaluate how these methods perform and scale in regards to our static approach as well as extract differentiating input towards test case generation applications -- 8 months.   
\item Combine static and dynamic analysis methods towards achieving better precision and extracting more differencing program input for automatic test case generation. Use static analysis directed symbolic execution for maximum scalability and precision -- 6 months
\COMMENT{
\item Extend our tool to run on array and pointer programs -- 5 months.
\item Explore correlation refinement guideless analysis for achieving better precision. -- 4 months.
}
\end{enumerate} 