\section{Related Work}\seclabel{Related}

Our work has been mainly inspired by recent work identifying program differencing as having vast security implications~\cite{BrumleyPoosankamSongZheng08,SongSunZhang09} as well as advancements made in the field of under-approximations of program equivalence~\cite{GodlinStrichman09, KawaguchiLahiriRebelo10, DwyerElbaumPerson08, EnglerRamos11}.

The problem of program differencing is fundamental~\cite{Hoare69} and early work mainly focused on computing syntactical difference~\cite{HuntMcIlroy75}. These solutions are an important stepping stone and we used syntactical diff as a means to achieve interleaving of programs in out correlating program for better analysis results. Another possibility for creating this program is to rely on the editing sequence that creates the new version from the original program~\cite{Horwitz90}. Horwitz was one of the first to present a technique for comparing two versions of a program, using a partitioning operation on a graph representation of programs, and classifying each change as either semantic or textual. This is an important preliminary work that can be used for better correlation between programs. The results however did not supply a semantic description of the change. Lahiri, Vaswani and Hoare \cite{DiffAnalysis} presented a high-level overview of the opportunities, applications and challenges of differential static analysis and point out many possible benefits to be gained from such work. This also positions differential analysis as an important emerging topic.

Jackson and Ladd~\cite{JacksonLadd94} proposed a tool for computing data dependencies between input and output variables and comparing these dependencies along versions of a program for discovering difference. This method may falsely report difference as semantic difference may occur even if data dependencies have not changed. Furthermore, data dependencies offer little insight as to the meaning of difference i.e. input and output values. Nevertheless, this was an important first step in employing program analysis as a means for semantic differencing.

Several works on the problem of equivalence of combinatorial circuits~\cite{KuehlmannKrohm97,BraytonChatterjeeMishchenkoEen06, ClarkeKroening03} made important contributions in establishing the problem of equivalence as feasible, producing practical solutions for hardware verification.

We rely on classic methods of abstract interpretation~\cite{CousotCousot77} for presenting an over approximating solution for semantic differencing and equivalence. To achieve this we devised a static analysis over a correlating program. The idea of a correlating program is similar to that of self-composition~\cite{AikenTerauchi05} except that we compose two different programs in a interleaving designed to maintain a close correlation between them. The use of a correlating construct for differencing is novel as previous methods mainly use sequential composition~\cite{GodlinStrichman09, DwyerElbaumPerson08, EnglerRamos11}, disregarding possible program correlation.

We base our analysis on numerical abstractions~\cite{CousotHalbwachs78, Mine2006} that allow us to reason about variables of different programs. The abstraction is further refined in a way similar to trace partitioning~\cite{MauborgneRival07} with an equivalence-based partitioning criteria.

Symbolic execution based methods~\cite{DwyerElbaumPerson08, EnglerRamos11} offer practical equivalence verification techniques for loop and recursion free programs with small state space. These works complement each other in regards to reporting difference as one ~\cite{DwyerElbaumPerson08} presents an over approximating description of difference they call differential summaries and the other~\cite{EnglerRamos11} presents an under approximating description including concrete inputs for test cases demonstrating difference in behavior. An interesting question is how could these methods be combined iteratively to achieve better precision. Also, this work can be used to complement our work in cases where equivalence could not be proven and the description of difference can be leveraged for the extraction of concrete input that leads to offending states.

Bounded model checking based work~\cite{GodlinStrichman09} presents the notion of partial equivalence which allows checking for equivalence under specific conditions, supplied by the user but are bound by loops. They employ a technique based on theorem provers for proving an equivalence formula which embeds program logic (in SSA form) alongside the requirement for input and output equivalence and user provided constraints.

\cite{AmitRinetzkyRepsSagivYahav07} introduced a correlating heap semantics for verifying linearizability of concurrent programs. In their work, a correlating heap semantics is used to establish correspondence between a concurrent program and a sequential version of the program at specific linearization points.



Kawaguchi, Lahiri and Rebelo \cite{CondEqv} defined the concept of \textit{conditional equivalence} meaning under which conditions (inputs) are 2 different versions of a program equivalent (i.e. produce the same output). Their goal is to keep software changes from breaking procedure contracts and changing module behavior too drastically and they achieve this by proposing a method for proving equivalence under certain conditions on the input. A key observation is that the input conditions must be supplied by the user and requires knowledge of the program and patch. We aim to infer conditions under which equivalence is broken and supply these back to the user or towards other applications as suggested. Another important difference is that we use a correlating domain that's able to track relationships between versions of variables which is potentially more expressive than their use of domains which separate variables.

Lahiri, Hawblitzel, Kawaguchi and Rebelo \cite{SymDiff} present a tool for semantic differencing called SYMDIFF. The tool is based on symbolic execution techniques and SMT solvers to present a trace (as opposed to our state which contains all traces) where two program differ from each other which means it is un-sound (it cannot handle loops for instance). The tool relies on the user for a correspondence between the two program procedures and variables.

Person, Dwyer, Elbaum and Pasareanu \cite{DBLP:conf/sigsoft/PersonDEP08} introduced an extension and application of symbolic execution techniques that computes a precise behavioral characterization of a program change called differential symbolic execution. As we also implemented bounded symbolic execution as our preliminary work discuss this method in comparison to our own.

Ramos and Engler \cite{DBLP:conf/cav/RamosE11} present a tool designed to check the equivalence of two arbitrary C functions by synthesizing inputs using symbolic execution to verify that they produce equivalent outputs on a finite number of paths.

Godlin and Strichman \cite{DBLP:conf/dac/GodlinS09} developed a method for proving the equivalence of similar C programs under certain restrictions based on and existing functional verification tool. This was a basis for future work regarding equivalence and we intend to base our work upon these advances.

Hayden, Magill, Hicks, Foster and Foster \cite{DBLP:conf/vstte/HaydenMHFF12} present a technique for establioshing thje correctness of dynamic software updates by creating a \emph{merged program} which contains the original program alongside the patch and then verifying a specification for that merged program using standard verification tools. This work focuses on specifications rather than describing change but their method of crating a merged program can be studied to propose a different program correlation algorithm.

Brumley, Poosankam, Song and Zheng \cite{AutoPatch} is the prominent work addressing patch-based analysis toward exploit generation. This work presents an attempt at generating a few inputs that trigger a bug in a pre-patched version. Their results are highly limited and only aim at bug patches with security implications, they do not model the difference in behavior nor supply a sound result which makes it applicable to the very limited scenario of patch based exploitation.

Kroening and Heelan \cite{AutoExploit} main focus was producing an exploit from given input that is known to trigger a bug. No patch is involved in the process. Our goal is to produce said input from the corrected software thus \cite{AutoExploit} can be used to create an exploit from our results.

Song, Zhang and Sun \cite{AutoBinary} also relate to the patch-based exploit generation problem but their main focus is on finding similarities between versions of the binary to better couple functions from the original program with their patched counter-part, a problem that was not addressed in \cite{AutoPatch}. Also their method of recognizing possible exploits is degenerate and relies on identifying known input validation functions that were added to a certain path - a method that could be easily overcome.
