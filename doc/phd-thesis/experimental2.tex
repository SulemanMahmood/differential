\section{Evaluation of Existing Work}\seclabel{Evaluation}
We have implemented our approach in a tool called {\tool}  based on the \sname{LLVM} compiler infrastructure and the \sname{APRON} numerical abstract domain library, and evaluated our approach on a number of challenging real world programs where the patches affect numerical variables. As benchmarks, we used several programs from the GNU core utilities (differencing versions 6.10 and 6.11), as well as a few handpicked patches taken from the Linux kernel and the Mozilla Firefox web browser. In most programs, we were able to precisely describe the difference.


\subsection{Results}

%\input{results-tab}

%\tabref{Results} summarizes the results of our analysis. The columns indicate the benchmark name and description, lines of code for the analyzed program, the number of lines added and removed by the patch, the number of diff-points generated, the numerical domain used, and the number of differences found in the analysis (i.e. number of diff-points where $\triangle \neq \varnothing$). In our benchmarks, we focused on computing intra-procedural difference between the two versions of procedures. Procedure calls presented difficulty as they potentially change global variables and local variables through pointers. We overcame this by either (i) assuming equivalence (alone) once we encounter a call to a procedure we already established as equivalent or (ii) warn that all results regarding variables touched by the procedure is un-sound. \TODO{In the majority of our benchmarks we identified calls only to library and system procedures thus we could omit their effect as they do not change variables beyond those given as parameter or those being assigned the return value.} All differences reported describe, in constraints over variables, an existing delta at that program point.

\paragraph{Producing delta from abstract state}

\input{code/linux}

\figref{LinuxExample} shows a patch made to the \scode{net/sunrpc/addr.c} module in the Linux kernel \scode{SUNRPC} implementation v2.6.32-rc6 which is aimed at removing an off-by-two array access out of bounds violation in the original program. Although simple, this example shows two advantages {\tool}: (i)~the ability to analyze programs without the need to run them and (ii)~the ability to capture fine-grained differences.\COMMENT{Previous methods would report equivalence for this patch, disregarding the array out of bounds access covered by the patch. Concrete methods~\cite{EnglerRamos11} would require symbolically running the two versions which would be problematic and time consuming considering the size of the system the code is embedded in.} The result of analyzing the correlated program is shown in~\figref{sunrpc}.

\begin{figure}[H]
\scriptsize
\centering
\begin{tabular}{c}
$\sigma_1$:
\\ \hline
returned' = $true$
\\
returned = $false$
\\
uaddr\_len' $\leq$ RPCBIND\_MAXUADDRLEN - 2
\\
uaddr\_len' $\geq$ RPCBIND\_MAXUADDRLEN
\\ \hline
\end{tabular}
\caption{Difference for \scode{rpc\_uaddr2sockaddr}}\label{Fi:sunrpc}

\end{figure}

The difference is captured by one sub-state where the execution has ended in the patched program but continues in the original. We instrument the correlating program with a return flag to capture the difference as otherwise equivalence holds (none of the original variables change).

\paragraph{Capturing complex delta}

\input{code/pr}

\figref{PrExample} shows a patch made to the \scode{char\_to\_clump} function in version 6.11 of coreutils. The patch replacing the execution of the line \scode{input\_position += width}, which originally executed unconditionally, with a conditional structure that in the new version, allows the line to execute only under certain complex conditions. Since the variables handled in this patch (the global \scode{input\_position} and return value \scode{chars}) emit output, describing how their values changed and under which terms is important, especially as the patch cannot be easily parsed by a programmer to understand its meaning. The result of our analysis at the return point is show in \figref{CharToClump}. These results include information regarding initial values of parameters for improved precision.

\begin{figure}[H]
\scriptsize
\centering
\begin{tabular}{l|l|l}
$\sigma_1$:                 & $\sigma_2$:                   & $\sigma_3$:
\\ \hline
input\_position${_0}$ = 0     & input\_position${_0}$  < -width & input\_position${_0}$  < -width
\\
chars' = 0                & input\_position${_0}$  < 0      & input\_position${_0}$  > 0
\\
input\_position = width   & input\_position' = 0        & input\_position' = 0
\\
input\_position < 0       & input\_position < width     & input\_position > width
\\
input\_position' = 0      & width < 0                   & input\_position <= 0
\\ \hline
\end{tabular}
\caption{Difference for coreutils pr.c \scode{char\_to\_clump}}\label{Fi:CharToClump}
\end{figure}


The result convey the difference in the output variable values alongside some of conditions under which the difference occurs. The result is composed of three sub-states featuring difference and adhere to two added paths in the patched program. The first sub-state belongs to the first branch in the added conditional: the difference is comprised of (i) the new value of \scode{input\_position} is 0 as opposed to it being \scode{width} in the former version (the analysis took the \scode{input\_position += width} line into account and incorporated knowing that $input\_position = 0$ from the branch condition). The analysis also deduced that the old \scode{input\_position} is negative under the same input as the branch condition dictates that \scode{width} is negative. (ii) \scode{chars} in the new program is 0 under this path. The two other sub-states adhere to the second added path in the conditional and track a difference for \scode{input\_position} alone, basically stating that \scode{input\_position} under this path used to assume values in ranges $[-\inf,width]$ and $[width,0]$ but now is simply 0. The splitting of this path into two cases is a result of expressing the non-convex $input\_position \neq 0$ condition from the first branch conditional using two sub-states. The result also describes constraints on the procedure's input under which the difference exist. Another product of the analysis, which we do not show here, are sub-states describing paths which the patch did not affect.

\paragraph{Maintaining Equivalence and Reporting Difference in Loops}

\input{code/md5sum}
We explore a challenging loop scenario where all paths in the programs contain loops and only some of them maintain equivalence. \figref{Md5sumExample} shows part of coreutils md5sum.c \scode{bsd\_split\_3} function that was patched in version version 6.11 to disallow 0-length inputs. Although this patch seems trivial, analyzing it is challenging as it affects the behavior of loops i.e. unbound path lengths. The main challenge in this example, is separating the path where $s\_len$ is 0, which results in the loop index $i$ ranging within negative values (producing an array access out of bounds fault), from the rest of the behaviors that maintain equivalence, throughout the widening process which is required for the analysis to reach a fixed point. The result of our analysis with partitioning is shown in \figref{bsdSplit}~(a) (per differencing points $(*)_{1},(*)_{2}$).

\begin{figure}[H]
\scriptsize
\centering
\begin{tabular}{c}
\begin{tabular}{l||l}
\begin{tabular}{l|l}
\multicolumn{2}{l}{$(*)_1$:}
\\ \hline
$\sigma_1$:     & $\sigma_2$ (equivalent):
\\ \hline
s\_len = 0      & s\_len' = s\_len
\\
s\_len' = 0     & i' = i
\\
i $\leq$ -1     & s\_len' - 1 $\geq$ i'
\\ \hline
\end{tabular}
&
\begin{tabular}{l}
\multicolumn{1}{l}{$(*)_2$:}
\\ \hline
$\sigma_1$ (equivalent):
\\ \hline
s\_len' = s\_len
\\
i' = i
\\
s\_len' - 1 $\geq$ i'
\\ \hline
\end{tabular}
\end{tabular}
\\ \\ (a) \\
\begin{tabular}{l||l}
\begin{tabular}{l|l|l}
\multicolumn{2}{l}{$(*)_1$:}
\\ \hline
$\sigma_1$:     & $\sigma_2$ (equivalent):  & $\sigma_3$ (equivalent):
\\ \hline
s\_len = 0      & s\_len' = s\_len          & s\_len' = s\_len
\\
s\_len' = 0     & i' = i                    & i = 0
\\
i $\leq$ -1     & s\_len' - 1 $\geq$ i'     & s\_len' $\geq$ 1
\\ \hline
\end{tabular}
&
\begin{tabular}{l}
\multicolumn{1}{l}{$(*)_2$:}
\\ \hline
$\sigma_1$ (equivalent):
\\ \hline
s\_len' = s\_len
\\
i' = i
\\
i = 0
\\
s\_len' $\geq$ 1
\\ \hline
\end{tabular}
\end{tabular}
\\ \\ (b)
\end{tabular}
\caption{Difference for \scode{bsd\_split\_3}}\label{Fi:bsdSplit}
\end{figure}

We can see the analysis successfully reports a difference for the singularity point $s\_len = 0$ inside the loop, precisely describing the scenario where $i'$ is negative. We can also see the other equivalent state existing within the loop which depicts the results of the widened analysis for all other paths (the $s\_len \neq 0$ constraint is not existing there due to partitioning as we will soon show). The differencing sub-state will be omitted once we move past the loop as the $i \leq -1$ constraint will not allow it to exist beyond the loop body \COMMENT{(we do not account for overflow at this point in our work as ???)} thus we are left with the equivalent state alone after the loop which correctly expresses the fact that the programs are equivalent at this point (since both i's converged at 0). We can see that the result at the second differencing point has lost precision since it does not reflect the $i = 0$ constraint. The loss of this constraint is, again, due to partitioning as both sub-states that describe exiting the loop and the one describing entering the loop, hold equivalence for all variables and are joined to together and lose the extra constraint information.
\COMMENT{? describe the canonization for the example}
If we analyze the same example with no partitioning we get the result of \figref{bsdSplit}~(b).

Which further separates the paths in the program, allowing for a different sub-state for the $i = 0$ and $i \neq 0$ substates (again, the $i \neq 0$ constraints was lost when joining together the $i > 0$ and $i < 0$ states as they both adhere to the same path and hold the same guard values). This extra precision is beneficial, but we still managed to supply a satisfactory result using the more scalable partitioning by equivalence technique.

%\input{results-tab}


